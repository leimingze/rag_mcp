# 核心特点

## RAG 策略与设计亮点

**分块策略：智能分块与上下文增强**
- **智能分块**：摒弃机械的定长切分，采用语义感知的切分策略以保证完整语义。
- **上下文增强**：为 chunk 注入文档元数据（标题、页码）和图片描述，确保检索时不仅匹配文本，还能感知上下文。

**粗排召回：混合检索**
- 结合**稀疏检索**（BM25）利用关键词精确匹配，解决专有名词查找问题。
- 结合**稠密检索**（语义向量）利用语义向量，解决同义词与模糊表达问题。
- 两者互补，通过 RRF 算法融合，确保查全率与查准率的平衡。

**精排重排**
- 采用 Cross-Encoder（专用重排模型）或 LLM Rerank 对候选集进行逐一打分，识别细微的语义差异。

## 全链路可插拔架构

**LLM 调用层可插拔**
- 核心推理 LLM 通过统一的抽象接口封装，支持多协议无缝切换：
  - Azure OpenAI：企业级 Azure 云端服务，符合合规与安全要求。
  - OpenAI API：直接对接 OpenAI 官方接口。
  - 本地部署：支持 Ollama、vLLM 等本地私有化部署方案。
  - 其他云服务：DeepSeek、Anthropic Claude、Zhipu 等第三方 API。
- 通过配置文件一键切换后端，零代码修改完成 LLM 迁移。

**Embedding & Rerank 可插拔**
- Embedding 模型与 Rerank 模型同样采用统一接口封装。
- 支持云端服务和本地服务自由切换。

**RAG Pipeline 组件可插拔**
- Loader（解析器）：支持 PDF、Markdown、Code 等多文档解析器独立替换。
- Smart Splitter（切分策略）：语义切分、定长切分、递归策略可配置。
- Transformation（元数据/图文增强逻辑）：OCR、Image Caption 等增强模块可独立配置。

**检索策略可插拔**
- 支持动态配置纯向量、纯关键词或混合检索模式。
- 支持灵活更换向量数据库后端（如从 Chroma 迁移至 Qdrant、Milvus）。

**评估体系可插拔**
- 评估模块不锁定单一指标，支持挂载不同的 Evaluator（如 Ragas、DeepEval）。

## MCP 生态集成

项目的设计核心完全遵循 MCP 标准，使得项目不仅是一个独立的问答服务，更是一个即插即用的知识上下文提供者。

**工作原理**
- Server 作为 MCP Server 运行，提供一组标准的 tools 和 resources 接口。
- MCP Clients（如 GitHub Copilot、Research Agent、Claude Desktop 等）可以直接连接到这个 Server。
- 无缝接入：当在 GitHub Copilot 中提问时，Copilot 作为一个 MCP Host，能够自动发现并调用 Server 提供的工具。

**优势**
- 无需前端开发，可直接复用 ChatUI 和 AI 助手。
- 上下文互通：Copilot 可以同时看到代码文件和知识库内容。

## 多模态图像处理

图像采用 Multi-Embedding 多模态向量策略，支持图→图、文→图、图→文的跨模态检索。

## 可观测性与可评估体系

避免黑盒问题，本项目致力于让每一次生成过程都透明可见且可量化。

**全链路白盒化**
- 记录并可视化 RAG 流水线的每一个中间状态：从 Query 改写，到 Hybrid Search 的初步召回列表，再到 Reranker 重新排序，最后到 LLM 的 Prompt 构建。
- 开发者可以清晰看到系统为什么选了这个文档以及 Rerank 起了什么作用，从而精确定位 Bad Case。

**自动化评估闭环**
- 集成 Ragas 等评估框架，为每一次检索和生成计算"体检报告"（召回率、准确率等指标）。
- 拒绝凭感觉调优，建立基于数据的迭代反馈回路，确保每一次策略调整都有量化分数支撑。

## 业务可扩展性

本项目采用通用化架构设计，不仅是一个开箱即用的知识问答系统，更是一个可以快速适配各类业务场景的扩展基座。
