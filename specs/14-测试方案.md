## 测试方案
### 设计理念：测试驱动开发 (TDD)
本项目采用**测试驱动开发（Test-Driven Development）**作为核心开发范式，确保每个组件在实现前就已明确其预期行为，通过自动化测试持续验证系统质量。
- 核心原则：
  - 早测试、常测试：每个功能模块实现的同时就编写对应的单元测试，而非事后补测。
  - 测试即文档：测试用例本身就是最准确的行为规范，新加入的开发者可通过阅读测试快速理解各模块功能。
  - 快速反馈循环：单元测试应在秒级完成，支持开发者高频执行，立即发现引入的问题。
  - 分层测试金字塔：大量快速的单元测试作为基座，少量关键路径的集成测试作为保障，极少数端到端测试验证完整流程。
        /\
       /E2E\         <- 少量，验证关键业务流程
      /------\
     /Integration\   <- 中量，验证模块协作
    /------------\
   /  Unit Tests  \  <- 大量，验证单个函数/类
  /________________\

### 测试分层策略
#### 单元测试 (Unit Tests)
目标：验证每个独立组件的内部逻辑正确性，隔离外部依赖。
- 覆盖范围：
| 模块 | 测试重点 | 典型测试用例 |
|------|---------|-------------|
| Loader (文档解析器) | 格式解析、元数据提取、图片引用收集 | - 测试解析单页/多页 PDF<br>- 验证 Markdown 标题层级提取<br>- 检查图片占位符插入位置 |
| Splitter (切分器) | 切分边界、上下文保留、元数据传递 | - 验证按标题切分不破坏段落<br>- 测试超长文本的递归切分<br>- 检查 Chunk 的 source 字段正确性 |
| Transform (增强器) | 图片描述生成、元数据注入 | - Mock Vision LLM，验证描述注入逻辑<br>- 测试无图片时的降级行为<br>- 验证幂等性（重复处理相同输入） |
| Embedding (向量化) | 批处理、差量计算、向量维度 | - 验证相同文本生成相同向量<br>- 测试批量请求的拆分与合并<br>- 检查缓存命中逻辑 |
| BM25 (稀疏编码) | 关键词提取、权重计算 | - 验证停用词过滤<br>- 测试 IDF 计算准确性<br>- 检查稀疏向量格式 |
| Retrieval (检索器) | 召回精度、融合算法 | - 测试纯 Dense/Sparse/Hybrid 三种模式<br>- 验证 RRF 融合分数计算<br>- 检查 Top-K 结果排序 |
| Reranker (重排器) | 分数归一化、降级回退 | - Mock Cross-Encoder，验证分数重排<br>- 测试超时后的 Fallback 逻辑<br>- 验证空候选集处理 |

- 技术选型：
  - 测试框架：pytest（Python 标准选择，支持参数化测试、Fixture 机制）
  - Mock 工具：unittest.mock / pytest-mock（隔离外部依赖，如 LLM API）
  - 断言增强：pytest-check（支持多断言不中断执行）
#### 集成测试 (Integration Tests)
目标：验证多个组件协作时的数据流转与接口兼容性。
| 测试场景 | 验证要点 | 测试策略 |
|---------|---------|---------|
| Ingestion Pipeline | Loader → Splitter → Transform → Storage 的完整流程 | - 使用真实的测试 PDF 文件<br>- 验证最终存入向量库的数据完整性<br>- 检查中间产物（如临时图片文件）是否正确清理 |
| Hybrid Search | Dense + Sparse 召回的融合结果 | - 准备已知答案的查询-文档对<br>- 验证融合后的 Top-1 是否命中正确文档<br>- 测试极端情况（某一路无结果） |
| Rerank Pipeline | 召回 → 过滤 → 重排的组合 | - 验证 Metadata 过滤后的候选集正确性<br>- 检查 Reranker 是否改变了 Top-1 结果<br>- 测试 Reranker 失败时的回退 |
| MCP Server | 工具调用的端到端流程 | - 模拟 MCP Client 发送 JSON-RPC 请求<br>- 验证返回的 content 格式符合协议<br>- 测试错误处理（如查询语法错误） |

- 技术选型：
  - 数据隔离：每个测试使用独立的临时数据库/向量库（pytest-tempdir）
  - 异步测试：pytest-asyncio（若 MCP Server 采用异步实现）
  - 契约测试：定义各模块间的 Schema，确保接口不漂移

####  端到端测试 (End-to-End Tests)
目标：模拟真实用户操作，验证完整业务流程的可用性。
核心场景：

- 场景 1：数据准备（离线摄取）

  测试目标：验证文档摄取流程的完整性与正确性
  测试步骤：
  准备测试文档（PDF 文件，包含文本、图片、表格等多种元素）
  执行离线摄取脚本，将文档导入知识库
  验证摄取结果：检查生成的 Chunk 数量、元数据完整性、图片描述生成
  验证存储状态：确认向量库和 BM25 索引正确创建
  验证幂等性：重复摄取同一文档，确保不产生重复数据
  验证要点：
  Chunk 的切分质量（语义完整性、上下文保留）
  元数据字段完整性（source、page、title、tags 等）
  图片处理结果（Caption 生成、Base64 编码存储）
  向量与稀疏索引的正确性
  
- 场景 2：召回测试
  测试目标：验证检索系统的召回精度与排序质量
  测试步骤：
  基于已摄取的知识库，准备一组测试查询（包含不同难度与类型）
  执行混合检索（Dense + Sparse + Rerank）
  验证召回结果：检查 Top-K 文档是否包含预期来源
  对比不同检索策略的效果（纯 Dense、纯 Sparse、Hybrid）
  验证 Rerank 的影响：对比重排前后的结果变化
  验证要点：
  Hit Rate@K：Top-K 结果命中率是否达标
  排序质量：正确答案是否排在前列（MRR、NDCG）
  边界情况处理：空查询、无结果查询、超长查询
  多模态召回：包含图片的文档是否能通过文本查询召回

- 场景 3：MCP Client 功能测试

  测试目标：验证 MCP Server 与 Client（如 GitHub Copilot）的协议兼容性与功能完整性
  测试步骤：
  启动 MCP Server（Stdio Transport 模式）
  模拟 MCP Client 发送各类 JSON-RPC 请求
  测试工具调用：query_knowledge_hub、list_collections 等
  验证返回格式：符合 MCP 协议规范（content 数组、structuredContent）
  测试引用透明性：返回结果包含完整的 Citation 信息
  测试多模态返回：包含图片的响应正确编码为 Base64
  验证要点：
  协议合规性：JSON-RPC 2.0 格式、错误码映射
  工具注册：tools/list 返回所有可用工具及其 Schema
  响应格式：TextContent 与 ImageContent 的正确组合
  错误处理：无效参数、超时、服务不可用等异常场景
  性能指标：单次请求的端到端延迟（含检索、重排、格式化）

- 测试工具：
  BDD 框架：behave 或 pytest-bdd（以 Gherkin 语法描述场景）
  环境准备：
  临时测试向量库（独立于生产数据）
  预置的标准测试文档集
  本地 MCP Server 进程（Stdio Transport）

### RAG 质量评估测试
目标：验证已设计的评估体系是否正确实现，并能有效评估 RAG 系统的召回与生成质量。
- 测试要点：

  - 黄金测试集准备
    构建标准的"问题-答案-来源文档"测试集（JSON 格式）
    初期人工标注核心场景，后期持续积累坏 Case

  - 评估框架实现验证
    验证 Ragas/DeepEval 等评估框架的正确集成
    确认评估接口能输出标准化的指标字典
    测试多评估器并行执行与结果汇总

  - 关键指标达标验证
    检索指标：Hit Rate@K ≥ 90%、MRR ≥ 0.8、NDCG@K ≥ 0.85
    生成指标：Faithfulness ≥ 0.9、Answer Relevancy ≥ 0.85
    定期运行评估，监控指标是否回归
说明：本节重点是验证评估体系的工程实现，而非重新设计评估方法（评估方法的设计见第 3 章技术选型）。
